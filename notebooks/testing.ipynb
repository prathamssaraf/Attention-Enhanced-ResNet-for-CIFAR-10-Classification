{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Attention Enhanced ResNet for CIFAR-10 Model Evaluation Notebook**\n",
    "\n",
    "### **A project by:**\n",
    "- **Karthik Krapa (kk5754)**\n",
    "- **Krish Murjani (km6520)**\n",
    "- **Pratham Saraf (ps5218)**\n",
    "\n",
    "This notebook focuses on evaluating and analyzing our trained model on the CIFAR-10 test dataset. We'll measure performance metrics, visualize predictions, and explore model behavior.\n",
    "\n",
    "## Setup and Environment Configuration\n",
    "\n",
    "We begin by importing necessary libraries for:\n",
    "- Data handling and manipulation (NumPy, Pandas, PIL)\n",
    "- Deep learning framework (PyTorch)\n",
    "- Visualization tools\n",
    "- Utility functions for efficient processing\n",
    "\n",
    "The code also configures the optimal computing device and sets random seeds for reproducible results across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.100404Z",
     "iopub.status.busy": "2025-03-14T07:06:58.100047Z",
     "iopub.status.idle": "2025-03-14T07:06:58.109299Z",
     "shell.execute_reply": "2025-03-14T07:06:58.108386Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.100365Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Components \n",
    "\n",
    "### Spatial Attention Module\n",
    "\n",
    "Loading the spatial attention mechanism from our training architecture. This module:\n",
    "\n",
    "- Focuses on important spatial regions within feature maps\n",
    "- Generates attention maps by combining channel-wise average and maximum activations\n",
    "- Uses a convolutional layer followed by sigmoid activation to create a spatial attention mask\n",
    "- Applies this mask to the input features, emphasizing important regions\n",
    "\n",
    "This attention mechanism helps the model focus on discriminative spatial locations in the input, enhancing feature representation without significantly increasing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.110794Z",
     "iopub.status.busy": "2025-03-14T07:06:58.110511Z",
     "iopub.status.idle": "2025-03-14T07:06:58.127874Z",
     "shell.execute_reply": "2025-03-14T07:06:58.126875Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.110774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        attention = torch.cat([avg_out, max_out], dim=1)\n",
    "        attention = self.conv(attention)\n",
    "        attention = self.sigmoid(attention)\n",
    "        \n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Residual Block\n",
    "\n",
    "Reconstructing the core building block of our network architecture. This block combines:\n",
    "\n",
    "1. **Standard Residual Pathway**:\n",
    "  - Two convolutional layers with batch normalization and ReLU\n",
    "  - Skip connection to facilitate gradient flow during training\n",
    "\n",
    "2. **Dual Attention Mechanism**:\n",
    "  - Channel attention: Captures interdependencies between feature channels\n",
    "    - Uses both average and max pooling for comprehensive feature aggregation\n",
    "    - Employs a bottleneck design with reduction ratio for efficiency\n",
    "  - Spatial attention: Emphasizes important regions in the feature maps\n",
    "    - Implemented using the previously defined SpatialAttention module\n",
    "\n",
    "3. **Adaptive Skip Connection**:\n",
    "  - Identity mapping when dimensions match\n",
    "  - 1×1 convolution with batch normalization for dimension matching\n",
    "\n",
    "This hybrid attention-enhanced residual block provides the network with the ability to focus on both what (channels) and where (spatial locations) is important in the feature representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.130005Z",
     "iopub.status.busy": "2025-03-14T07:06:58.129700Z",
     "iopub.status.idle": "2025-03-14T07:06:58.152267Z",
     "shell.execute_reply": "2025-03-14T07:06:58.151663Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.129983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(AttentionResidualBlock, self).__init__()\n",
    "        \n",
    "        # Main path\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Channel attention\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        reduction = max(out_channels // 16, 4)  \n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels // reduction, out_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Spatial attention\n",
    "        self.spatial_attention = SpatialAttention(kernel_size=7)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # Main path\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Channel attention\n",
    "        avg_out = self.channel_attention(self.avg_pool(out))\n",
    "        max_out = self.channel_attention(self.max_pool(out))\n",
    "        out = out * (avg_out + max_out)\n",
    "        \n",
    "        # Spatial attention\n",
    "        out = self.spatial_attention(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        identity = self.shortcut(identity)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Efficient ResNet Model\n",
    "\n",
    "Reconstructing our complete model architecture for evaluation. This custom ResNet variant features:\n",
    "\n",
    "1. **Network Structure**:\n",
    "  - Initial 3×3 convolution maintaining spatial dimensions\n",
    "  - Four stages of attention-enhanced residual blocks:\n",
    "    - Layer 1: 2 blocks (base_width → base_width*2)\n",
    "    - Layer 2: 2 blocks with downsampling (base_width*2 → base_width*4)\n",
    "    - Layer 3: 2 blocks with downsampling (base_width*4 → base_width*8)\n",
    "    - Layer 4: 2 blocks maintaining feature map size (base_width*8 → base_width*8)\n",
    "  - Classification head with global average pooling, dropout (30%), and fully connected layer\n",
    "\n",
    "2. **Design Considerations**:\n",
    "  - Base width of 32 channels (slightly different from training)\n",
    "  - Strategic downsampling placement to balance spatial information and feature abstraction\n",
    "  - Consistent use of attention mechanisms throughout the network\n",
    "\n",
    "This architecture balances model size, computational efficiency, and representational power for the CIFAR-10 classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.153888Z",
     "iopub.status.busy": "2025-03-14T07:06:58.153563Z",
     "iopub.status.idle": "2025-03-14T07:06:58.173471Z",
     "shell.execute_reply": "2025-03-14T07:06:58.172721Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.153858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EnhancedEfficientResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, base_width=32):\n",
    "        super(EnhancedEfficientResNet, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(3, base_width, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(base_width)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Layers\n",
    "        self.layer1 = self._make_layer(base_width, base_width*2, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(base_width*2, base_width*4, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(base_width*4, base_width*8, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(base_width*8, base_width*8, 2, stride=1)  \n",
    "        \n",
    "        # Global pooling and classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(base_width*8, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
    "        layers = [\n",
    "            AttentionResidualBlock(in_channels, out_channels, stride)\n",
    "        ]\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                AttentionResidualBlock(out_channels, out_channels)\n",
    "            )\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model Architecture\n",
    "\n",
    "This section includes our earlier version of the model for compatibility with previously saved weights and comparison purposes. The architecture consists of:\n",
    "\n",
    "### ChannelAttentionBlock\n",
    "- Similar to the enhanced version but with only channel attention (no spatial attention)\n",
    "- Uses residual connections and dual-pooling channel attention mechanism\n",
    "- Maintains the bottleneck design for efficiency in the attention module\n",
    "\n",
    "### EfficientResNet\n",
    "- The baseline architecture with three main layers (vs. four in the enhanced version)\n",
    "- Similar initial convolution and feature extraction pathway\n",
    "- Differences from the enhanced version:\n",
    " - Uses ChannelAttentionBlock instead of AttentionResidualBlock\n",
    " - Has one fewer layer (missing layer4)\n",
    " - Uses 25% dropout rate (vs. 30% in the enhanced version)\n",
    " - May have slightly different parameter counts\n",
    "\n",
    "Keeping this version allows us to:\n",
    "1. Load weights from earlier experiments\n",
    "2. Perform comparative analysis between model iterations\n",
    "3. Ensure backward compatibility with any saved checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.174565Z",
     "iopub.status.busy": "2025-03-14T07:06:58.174328Z",
     "iopub.status.idle": "2025-03-14T07:06:58.196146Z",
     "shell.execute_reply": "2025-03-14T07:06:58.195494Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.174534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ChannelAttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ChannelAttentionBlock, self).__init__()\n",
    "        \n",
    "        # Main path\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Channel attention\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        reduction = max(out_channels // 16, 4) \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels // reduction, out_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # Main path\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Channel attention\n",
    "        avg_out = self.attention(self.avg_pool(out))\n",
    "        max_out = self.attention(self.max_pool(out))\n",
    "        out = out * (avg_out + max_out)\n",
    "        \n",
    "        # Residual connection\n",
    "        identity = self.shortcut(identity)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class EfficientResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, base_width=32):\n",
    "        super(EfficientResNet, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(3, base_width, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(base_width)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Layers\n",
    "        self.layer1 = self._make_layer(base_width, base_width*2, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(base_width*2, base_width*4, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(base_width*4, base_width*8, 2, stride=2)\n",
    "        \n",
    "        # Global pooling and classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc = nn.Linear(base_width*8, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n",
    "        layers = [\n",
    "            ChannelAttentionBlock(in_channels, out_channels, stride)\n",
    "        ]\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                ChannelAttentionBlock(out_channels, out_channels)\n",
    "            )\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Time Augmentation (TTA) Configuration\n",
    "\n",
    "Test-Time Augmentation is a powerful technique that improves model robustness by averaging predictions across multiple transformed versions of the same input image. Our TTA setup includes:\n",
    "\n",
    "### Base Normalization\n",
    "- Using CIFAR-10 dataset statistics (mean and standard deviation) for consistent preprocessing\n",
    "\n",
    "### Augmentation Ensemble\n",
    "Eight strategic transformations applied during inference:\n",
    "\n",
    "1. **Original Image**: Standard preprocessing with normalization only\n",
    "2. **Horizontal Flip**: Exploits horizontal symmetry in natural images\n",
    "3. **Crop Variation 1**: Random crop with reflection padding to test positional robustness\n",
    "4. **Crop Variation 2**: Random crop with edge padding for different boundary handling\n",
    "5. **Minor Rotation 1**: Small 5° rotation to test orientation robustness\n",
    "6. **Minor Rotation 2**: Slightly larger 10° rotation for diverse angle perspectives\n",
    "7. **Color Variation 1**: Brightness, contrast, saturation, and hue adjustments\n",
    "8. **Color Variation 2**: Alternative color profile with different emphasis on contrast\n",
    "\n",
    "This diverse set of transformations helps the model account for various image variations that might occur in real-world scenarios, leading to more reliable predictions through ensemble averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.197190Z",
     "iopub.status.busy": "2025-03-14T07:06:58.196927Z",
     "iopub.status.idle": "2025-03-14T07:06:58.218183Z",
     "shell.execute_reply": "2025-03-14T07:06:58.217242Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.197170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_normalization = transforms.Normalize(\n",
    "    mean=(0.4914, 0.4822, 0.4465), \n",
    "    std=(0.2023, 0.1994, 0.2010)\n",
    ")\n",
    "\n",
    "# Advanced test-time augmentation transforms\n",
    "advanced_transforms = [\n",
    "    # 1. Original transform \n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "    # 2. Horizontal flip\n",
    "    transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "    # 3. Small crop 1\n",
    "    transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "    # 4. Small crop 2 \n",
    "    transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4, padding_mode='edge'),\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "    # 5. Slight rotate 1\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "    # 6. Slight rotate 2\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "    # 7. Color jitter\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "    # 8. Color jitter 2\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.05, contrast=0.15, saturation=0.05, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        test_normalization,\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced CIFAR-10 Test Dataset Implementation\n",
    "\n",
    "This custom Dataset class provides robust handling of test data with several improvements:\n",
    "\n",
    "### Advanced Features:\n",
    "- **Flexible Data Loading**: Handles pickle-formatted CIFAR test data with comprehensive error handling\n",
    "- **Format Adaptability**: Automatically detects and reshapes data between flat (3072-dimensional) and structured (3×32×32) formats\n",
    "- **Error Resilience**: Implements graceful fallback mechanisms to prevent pipeline failures\n",
    "- **ID Preservation**: Maintains original image identifiers for accurate submission generation\n",
    "\n",
    "### Error Handling Strategy:\n",
    "- Detailed error reporting during data loading and image processing\n",
    "- Fallback to zero tensors when individual images fail to process\n",
    "- Proper format conversion between NumPy arrays and PIL Images\n",
    "\n",
    "This implementation ensures reliable data loading and preprocessing even when dealing with potentially problematic test files, making the evaluation pipeline more robust against unexpected data issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.219623Z",
     "iopub.status.busy": "2025-03-14T07:06:58.219292Z",
     "iopub.status.idle": "2025-03-14T07:06:58.237754Z",
     "shell.execute_reply": "2025-03-14T07:06:58.237117Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.219591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EnhancedCIFARTestDataset(Dataset):\n",
    "    def __init__(self, pkl_file_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pkl_file_path (string): Path to the .pkl file containing test data\n",
    "            transform (callable, optional): Transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "        try:\n",
    "            with open(pkl_file_path, 'rb') as f:\n",
    "                data = pickle.load(f, encoding='bytes')\n",
    "            \n",
    "            self.images = data[b'data']\n",
    "            self.ids = data[b'ids'] if b'ids' in data else np.arange(len(self.images))\n",
    "            \n",
    "            if len(self.images.shape) == 2:\n",
    "                print(f\"Reshaping flat images of shape {self.images.shape}\")\n",
    "                self.images = self.images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "                print(f\"Reshaped to {self.images.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = self.images[idx]\n",
    "            if not isinstance(image, Image.Image):\n",
    "                image = Image.fromarray(image.astype('uint8'))\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, self.ids[idx]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {idx}: {e}\")\n",
    "            if self.transform:\n",
    "                return torch.zeros(3, 32, 32), self.ids[idx]\n",
    "            else:\n",
    "                return np.zeros((32, 32, 3), dtype=np.uint8), self.ids[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Test-Time Augmentation (TTA) Prediction\n",
    "\n",
    "This function implements a sophisticated prediction pipeline that leverages multiple augmented views of each test image to produce more robust classifications.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "1. **Weighted Ensemble Averaging**:\n",
    "  - Assigns double weight (2.0) to predictions from the original image\n",
    "  - Normalizes weights to ensure proper probability distribution\n",
    "  - Combines predictions by weighted averaging of softmax probabilities\n",
    "\n",
    "2. **Temperature Scaling**:\n",
    "  - Applies softmax temperature scaling (T=0.9) to calibrate confidence scores\n",
    "  - Lower temperature increases confidence in high-probability predictions\n",
    "  - Helps balance between confidence and uncertainty in the final ensemble\n",
    "\n",
    "3. **Memory Optimization**:\n",
    "  - Employs smaller batch sizes (32) to prevent out-of-memory errors\n",
    "  - Explicitly releases GPU memory after each augmentation pass\n",
    "  - Uses garbage collection to free CPU memory during long processing runs\n",
    "\n",
    "4. **Workflow Management**:\n",
    "  - Progress tracking with tqdm for each augmentation pipeline\n",
    "  - Flexible configuration of augmentation count via num_transforms parameter\n",
    "  - Maintains consistent image IDs across all augmentations for proper alignment\n",
    "\n",
    "This comprehensive approach produces state-of-the-art results by combining multiple perspectives of each image, significantly improving robustness against variations in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.239864Z",
     "iopub.status.busy": "2025-03-14T07:06:58.239636Z",
     "iopub.status.idle": "2025-03-14T07:06:58.261434Z",
     "shell.execute_reply": "2025-03-14T07:06:58.260649Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.239845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def enhanced_tta_prediction(model, pkl_file_path, output_filename=\"enhanced_submission.csv\", num_transforms=8):\n",
    "    \"\"\"\n",
    "    Advanced test-time augmentation with weighted averaging of predictions\n",
    "    \"\"\"\n",
    "    print(\"Starting enhanced TTA prediction...\")\n",
    "    model.eval()\n",
    "    \n",
    "    transforms_to_use = advanced_transforms[:num_transforms]\n",
    "    \n",
    "    weights = [2.0] \n",
    "    weights.extend([1.0] * (len(transforms_to_use) - 1))\n",
    "    \n",
    "    weights = [w / sum(weights) for w in weights]\n",
    "    \n",
    "    all_probs = []\n",
    "    image_ids = None\n",
    "    \n",
    "    for i, transform in enumerate(tqdm(transforms_to_use, desc=\"Processing augmentations\")):\n",
    "        dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=transform)\n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=32,  \n",
    "            shuffle=False, \n",
    "            num_workers=2, \n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        batch_probs = []\n",
    "        batch_ids = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, ids in dataloader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                outputs = outputs / 0.9  \n",
    "                \n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                \n",
    "                batch_probs.append(probs.cpu().numpy())\n",
    "                batch_ids.append(ids.numpy())\n",
    "                \n",
    "                del images, outputs, probs\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        augmentation_probs = np.concatenate(batch_probs)\n",
    "        \n",
    "        all_probs.append(augmentation_probs * weights[i])\n",
    "        \n",
    "        if image_ids is None:\n",
    "            image_ids = np.concatenate(batch_ids)\n",
    "        \n",
    "        del batch_probs, augmentation_probs\n",
    "        gc.collect()\n",
    "    \n",
    "    avg_probs = np.sum(all_probs, axis=0)\n",
    "    final_preds = np.argmax(avg_probs, axis=1)\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': image_ids, \n",
    "        'Labels': final_preds\n",
    "    })\n",
    "    submission_df = submission_df.sort_values('ID')\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Enhanced TTA submission file created: {output_filename}\")\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Specialized Prediction Strategy\n",
    "\n",
    "This advanced prediction approach combines efficiency with accuracy by applying different levels of augmentation based on prediction confidence:\n",
    "\n",
    "### Two-Stage Prediction Pipeline:\n",
    "\n",
    "1. **Initial Confidence Assessment**:\n",
    "   - First pass uses only the base transform for all images\n",
    "   - Classifies each image and records prediction confidence\n",
    "   - Applies class-specific confidence thresholds based on known difficulty patterns\n",
    "   \n",
    "2. **Targeted Enhancement**:\n",
    "   - Identifies low-confidence predictions that fall below class-specific thresholds\n",
    "   - Only applies full TTA (all transforms) to these uncertain cases\n",
    "   - Skips unnecessary processing for already confident predictions\n",
    "   - Uses temperature scaling (T=1.2) to balance confidence in the ensemble\n",
    "\n",
    "## Class-Aware Confidence Thresholds:\n",
    "- Different thresholds for each class based on empirical confusion patterns:\n",
    "  - Higher thresholds (0.85-0.90) for visually distinct classes (airplane, automobile, ship, truck)\n",
    "  - Lower thresholds (0.70-0.75) for challenging classes (cat, dog, bird, deer)\n",
    "\n",
    "This hybrid approach significantly reduces computational overhead compared to full TTA on all samples while maintaining high accuracy by focusing augmentation resources on the most uncertain predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.262752Z",
     "iopub.status.busy": "2025-03-14T07:06:58.262465Z",
     "iopub.status.idle": "2025-03-14T07:06:58.276473Z",
     "shell.execute_reply": "2025-03-14T07:06:58.275808Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.262732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def class_specialized_prediction(model, pkl_file_path, output_filename=\"specialized_submission.csv\"):\n",
    "    \"\"\"\n",
    "    Creates predictions with specialized handling for different classes based on confidence thresholds\n",
    "    \"\"\"\n",
    "    print(\"Starting class-specialized prediction...\")\n",
    "    model.eval()\n",
    "    \n",
    "    base_transform = advanced_transforms[0]\n",
    "    dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=base_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    initial_preds = []\n",
    "    confidence_scores = []\n",
    "    image_ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, ids in tqdm(dataloader, desc=\"Initial prediction pass\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            values, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            initial_preds.extend(preds.cpu().numpy())\n",
    "            confidence_scores.extend(values.cpu().numpy())\n",
    "            image_ids.extend(ids.numpy())\n",
    "            \n",
    "            del images, outputs, probs, values, preds\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    # Confidence thresholds for different classes\n",
    "    class_confidence_thresholds = {\n",
    "        0: 0.85,  # airplane\n",
    "        1: 0.90,  # automobile\n",
    "        2: 0.75,  # bird - still relatively difficult\n",
    "        3: 0.70,  # cat - difficult class\n",
    "        4: 0.75,  # deer\n",
    "        5: 0.70,  # dog - difficult class\n",
    "        6: 0.85,  # frog\n",
    "        7: 0.85,  # horse\n",
    "        8: 0.90,  # ship\n",
    "        9: 0.90,  # truck\n",
    "    }\n",
    "    \n",
    "    low_conf_indices = []\n",
    "    for i, (pred, conf) in enumerate(zip(initial_preds, confidence_scores)):\n",
    "        if conf < class_confidence_thresholds.get(pred, 0.75):\n",
    "            low_conf_indices.append(i)\n",
    "    \n",
    "    print(f\"Found {len(low_conf_indices)} low confidence predictions ({len(low_conf_indices)/len(initial_preds)*100:.2f}%)\")\n",
    "    \n",
    "    final_preds = list(initial_preds)\n",
    "    \n",
    "    if low_conf_indices:\n",
    "        low_conf_probs = []\n",
    "        \n",
    "        for transform in tqdm(advanced_transforms, desc=\"Processing difficult cases\"):\n",
    "            dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=transform)\n",
    "            dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
    "            \n",
    "            all_outputs = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, _) in enumerate(dataloader):\n",
    "                    batch_start = batch_idx * 64\n",
    "                    batch_end = min(batch_start + 64, len(dataset))\n",
    "                    batch_indices = list(range(batch_start, batch_end))\n",
    "                    \n",
    "                    process_batch = any(idx in low_conf_indices for idx in batch_indices)\n",
    "                    \n",
    "                    if process_batch:\n",
    "                        images = images.to(device)\n",
    "                        outputs = model(images)\n",
    "                        all_outputs.append(outputs.cpu())\n",
    "                    else:\n",
    "                        all_outputs.append(torch.zeros(len(batch_indices), 10))\n",
    "            \n",
    "            all_outputs = torch.cat(all_outputs)\n",
    "            \n",
    "            selected_outputs = all_outputs[low_conf_indices]\n",
    "            selected_probs = F.softmax(selected_outputs / 1.2, dim=1).numpy()  \n",
    "            \n",
    "            low_conf_probs.append(selected_probs)\n",
    "        \n",
    "\n",
    "            del all_outputs, selected_outputs, selected_probs\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_probs = np.mean(np.stack(low_conf_probs), axis=0)\n",
    "        improved_preds = np.argmax(avg_probs, axis=1)\n",
    "        \n",
    "        for i, idx in enumerate(low_conf_indices):\n",
    "            final_preds[idx] = improved_preds[i]\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': image_ids, \n",
    "        'Labels': final_preds\n",
    "    })\n",
    "    submission_df = submission_df.sort_values('ID')\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Class-specialized submission file created: {output_filename}\")\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Multi-Strategy Prediction System\n",
    "\n",
    "This section implements our most sophisticated prediction approach - a hybrid system that adaptively combines multiple prediction strategies to maximize accuracy.\n",
    "\n",
    "### Four-Phase Pipeline:\n",
    "\n",
    "1. **Model Loading with Fail-safe Mechanism**:\n",
    "  - Attempts to load using the enhanced architecture first\n",
    "  - Falls back to original architecture if needed\n",
    "  - Includes additional fallback options for different checkpoint formats\n",
    "  - Handles strict and non-strict loading for maximum compatibility\n",
    "\n",
    "2. **Dual Prediction Generation**:\n",
    "  - Performs full enhanced TTA with all eight transforms\n",
    "  - Executes class-specialized prediction with targeted augmentation\n",
    "  - Saves intermediate results to temporary files\n",
    "\n",
    "3. **Confidence-Based Integration**:\n",
    "  - Computes confidence scores for all predictions\n",
    "  - Applies class-specific confidence boosting for challenging categories (birds, cats, dogs)\n",
    "  - Uses tiered confidence thresholds (HIGH_CONF: 0.95, MED_CONF: 0.80)\n",
    "\n",
    "4. **Intelligent Decision Logic**:\n",
    "  - Uses agreement between methods as primary signal\n",
    "  - Prioritizes predictions with very high confidence\n",
    "  - Handles disagreements based on confidence differentials\n",
    "  - Implements special handling for traditionally difficult classes\n",
    "\n",
    "This adaptive approach combines the strengths of multiple prediction strategies, producing more reliable results than any single method alone, particularly for edge cases and challenging images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.277563Z",
     "iopub.status.busy": "2025-03-14T07:06:58.277328Z",
     "iopub.status.idle": "2025-03-14T07:06:58.300196Z",
     "shell.execute_reply": "2025-03-14T07:06:58.299560Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.277533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def adaptive_prediction(model_path, pkl_file_path, output_filename=\"adaptive_submission.csv\"):\n",
    "    \"\"\"\n",
    "    Creates predictions using an adaptive approach that combines multiple techniques\n",
    "    \"\"\"\n",
    "    print(\"Starting adaptive prediction process...\")\n",
    "    \n",
    "    try:\n",
    "        model = EnhancedEfficientResNet(num_classes=10)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(\"Successfully loaded model with enhanced architecture\")\n",
    "    except:\n",
    "        try:\n",
    "            model = EfficientResNet(num_classes=10)\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            print(\"Successfully loaded model with original architecture\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Attempting alternative loading method...\")\n",
    "            \n",
    "            model = EnhancedEfficientResNet(num_classes=10)\n",
    "            state_dict = torch.load(model_path, map_location=device)\n",
    "            if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n",
    "                model.load_state_dict(state_dict['state_dict'])\n",
    "            else:\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "                print(\"Warning: Model loaded with strict=False, some weights may not be loaded\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Step 1: Run enhanced TTA\n",
    "    print(\"\\nStep 1: Running enhanced TTA prediction...\")\n",
    "    enhanced_tta_prediction(model, pkl_file_path, \"tmp_tta.csv\", num_transforms=8)\n",
    "    \n",
    "    # Step 2: Run class-specialized prediction\n",
    "    print(\"\\nStep 2: Running class-specialized prediction...\")\n",
    "    class_specialized_prediction(model, pkl_file_path, \"tmp_spec.csv\")\n",
    "    \n",
    "    # Step 3: Combine predictions based on confidence\n",
    "    print(\"\\nStep 3: Combining predictions adaptively...\")\n",
    "\n",
    "    tta_df = pd.read_csv(\"tmp_tta.csv\")\n",
    "    spec_df = pd.read_csv(\"tmp_spec.csv\")\n",
    "    \n",
    "    tta_df = tta_df.sort_values('ID')\n",
    "    spec_df = spec_df.sort_values('ID')\n",
    "    \n",
    "    base_transform = advanced_transforms[0]\n",
    "    dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=base_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    all_probs = []\n",
    "    all_ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, ids in tqdm(dataloader, desc=\"Computing confidence scores\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_ids.extend(ids.numpy())\n",
    "    \n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    id_to_index = {id_val: i for i, id_val in enumerate(all_ids)}\n",
    "    \n",
    "    final_labels = []\n",
    "    \n",
    "    HIGH_CONF = 0.95 \n",
    "    MED_CONF = 0.80   \n",
    "    \n",
    "    class_boost = {\n",
    "        2: 0.05,  # bird\n",
    "        3: 0.05,  # cat\n",
    "        5: 0.05,  # dog\n",
    "    }\n",
    "    \n",
    "    for i in range(len(tta_df)):\n",
    "        img_id = tta_df.iloc[i]['ID']\n",
    "        tta_pred = tta_df.iloc[i]['Labels']\n",
    "        spec_pred = spec_df.loc[spec_df['ID'] == img_id, 'Labels'].values[0]\n",
    "        \n",
    "        idx = id_to_index[img_id]\n",
    "        prob_vector = all_probs[idx]\n",
    "        \n",
    "        tta_conf = prob_vector[tta_pred]\n",
    "        if tta_pred in class_boost:\n",
    "            tta_conf += class_boost[tta_pred]\n",
    "            \n",
    "        spec_conf = prob_vector[spec_pred]\n",
    "        if spec_pred in class_boost:\n",
    "            spec_conf += class_boost[spec_pred]\n",
    "        \n",
    "        # Decision logic\n",
    "        if tta_pred == spec_pred:\n",
    "            final_labels.append(tta_pred)\n",
    "        elif tta_conf > HIGH_CONF:\n",
    "            final_labels.append(tta_pred)\n",
    "        elif spec_conf > HIGH_CONF:\n",
    "            final_labels.append(spec_pred)\n",
    "        elif tta_conf > MED_CONF and tta_conf > spec_conf:\n",
    "            final_labels.append(tta_pred)\n",
    "        elif spec_conf > MED_CONF and spec_conf > tta_conf:\n",
    "            final_labels.append(spec_pred)\n",
    "        elif tta_pred in [2, 3, 5]:\n",
    "            final_labels.append(spec_pred)\n",
    "        else:\n",
    "            final_labels.append(tta_pred)\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': tta_df['ID'],\n",
    "        'Labels': final_labels\n",
    "    })\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    if os.path.exists(\"tmp_tta.csv\"):\n",
    "        os.remove(\"tmp_tta.csv\")\n",
    "    if os.path.exists(\"tmp_spec.csv\"):\n",
    "        os.remove(\"tmp_spec.csv\")\n",
    "    \n",
    "    print(f\"Adaptive submission file created: {output_filename}\")\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Method Ensemble Generation\n",
    "\n",
    "This function creates a diverse ensemble of predictions using different strategies to maximize our chances of correct classification. Ensemble methods improve robustness by leveraging the \"wisdom of crowds\" principle where different approaches compensate for each other's weaknesses.\n",
    "\n",
    "### Generated Prediction Set:\n",
    "\n",
    "1. **Enhanced TTA Prediction**:\n",
    "  - Implements test-time augmentation with a reduced set of 6 transforms\n",
    "  - Uses different transform count than the adaptive method (8) to increase prediction diversity\n",
    "  - Provides strong baseline predictions with well-balanced augmentation\n",
    "\n",
    "2. **Class-Specialized Prediction**:\n",
    "  - Focuses computational resources on difficult cases\n",
    "  - Uses class-specific confidence thresholds\n",
    "  - Handles challenging classes with targeted processing\n",
    "\n",
    "3. **Adaptive Fusion Prediction**:\n",
    "  - Combines the strengths of both methods\n",
    "  - Uses sophisticated decision logic with confidence thresholds\n",
    "  - Applies special handling for known difficult classes\n",
    "\n",
    "This diverse set of predictions creates a foundation for final submission selection or voting-based ensemble combination, allowing us to select the most effective approach based on validation performance or combine them for further accuracy improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.301274Z",
     "iopub.status.busy": "2025-03-14T07:06:58.301005Z",
     "iopub.status.idle": "2025-03-14T07:06:58.320520Z",
     "shell.execute_reply": "2025-03-14T07:06:58.319985Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.301246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_multiple_predictions(model_path, pkl_file_path, base_filename=\"submission\"):\n",
    "    \"\"\"\n",
    "    Generates multiple prediction files using different methods for final ensemble\n",
    "    \"\"\"\n",
    "    print(\"Generating multiple predictions for ensemble...\")\n",
    "    \n",
    "    try:\n",
    "        model = EnhancedEfficientResNet(num_classes=10)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    except:\n",
    "        model = EfficientResNet(num_classes=10)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    enhanced_tta_prediction(\n",
    "        model, \n",
    "        pkl_file_path, \n",
    "        f\"{base_filename}_tta.csv\",\n",
    "        num_transforms=6  \n",
    "    )\n",
    "    \n",
    "    class_specialized_prediction(\n",
    "        model,\n",
    "        pkl_file_path,\n",
    "        f\"{base_filename}_spec.csv\"\n",
    "    )\n",
    "    \n",
    "    adaptive_prediction(\n",
    "        model_path,\n",
    "        pkl_file_path,\n",
    "        f\"{base_filename}_adaptive.csv\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Generated 3 prediction files for ensemble submission\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Voting System\n",
    "\n",
    "This function implements a democratic voting ensemble to combine multiple prediction files into a final consensus prediction. Ensemble methods are a proven technique in machine learning that can significantly improve accuracy by reducing individual model biases.\n",
    "\n",
    "### Ensemble Process:\n",
    "\n",
    "1. **Input Validation**:\n",
    "  - Loads all prediction files and ensures consistent sorting by ID\n",
    "  - Performs strict verification that all files contain identical image IDs\n",
    "  - Prepares predictions for majority voting\n",
    "\n",
    "2. **Majority Voting Algorithm**:\n",
    "  - Stacks predictions from all methods for each sample\n",
    "  - Determines the most frequent class prediction for each image\n",
    "  - Resolves ties by selecting the first occurrence of the maximum count\n",
    "\n",
    "3. **Result Generation**:\n",
    "  - Creates a consolidated submission file with consensus predictions\n",
    "  - Maintains the original image ID ordering\n",
    "\n",
    "This majority voting approach counteracts individual method weaknesses by leveraging collective intelligence - when multiple methods agree on a prediction, it's more likely to be correct, while disagreements are resolved democratically based on the most common prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.321561Z",
     "iopub.status.busy": "2025-03-14T07:06:58.321287Z",
     "iopub.status.idle": "2025-03-14T07:06:58.342143Z",
     "shell.execute_reply": "2025-03-14T07:06:58.341415Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.321533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def ensemble_prediction_files(file_paths, output_filename=\"ensemble_submission.csv\"):\n",
    "    \"\"\"\n",
    "    Ensembles multiple prediction CSV files\n",
    "    \"\"\"\n",
    "    print(f\"Creating ensemble from {len(file_paths)} prediction files...\")\n",
    "    \n",
    "    dataframes = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.sort_values('ID')\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    for i in range(1, len(dataframes)):\n",
    "        assert np.array_equal(dataframes[0]['ID'].values, dataframes[i]['ID'].values), \"ID mismatch between files\"\n",
    "    \n",
    "    all_preds = np.array([df['Labels'].values for df in dataframes])\n",
    "    \n",
    "    final_preds = []\n",
    "    for i in range(len(dataframes[0])):\n",
    "        sample_preds = all_preds[:, i]\n",
    "        values, counts = np.unique(sample_preds, return_counts=True)\n",
    "        max_count_idx = np.argmax(counts)\n",
    "        final_preds.append(values[max_count_idx])\n",
    "    \n",
    "    ensemble_df = pd.DataFrame({\n",
    "        'ID': dataframes[0]['ID'],\n",
    "        'Labels': final_preds\n",
    "    })\n",
    "    ensemble_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Ensemble submission file created: {output_filename}\")\n",
    "    return ensemble_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Analysis Tool\n",
    "\n",
    "This utility function helps us understand and visualize differences between our various prediction methods, providing insights into model behavior and potential areas for improvement.\n",
    "\n",
    "### Analysis Components:\n",
    "\n",
    "1. **Agreement Rate Calculation**:\n",
    "  - Measures the percentage of images where all prediction methods agree\n",
    "  - Higher agreement rates generally indicate more confident and reliable predictions\n",
    "\n",
    "2. **Class-Specific Disagreement Analysis**:\n",
    "  - Identifies which classes experience the most prediction inconsistency\n",
    "  - Helps pinpoint challenging categories where models struggle to reach consensus\n",
    "  - Uses CIFAR-10 class names for intuitive reporting\n",
    "\n",
    "3. **Diagnostic Insights**:\n",
    "  - Allows identification of systematic weaknesses across different prediction strategies\n",
    "  - Provides guidance for method selection or targeted improvements\n",
    "\n",
    "This analysis is crucial for understanding ensemble dynamics and can inform decisions about which prediction strategies to prioritize or how to weight different methods in the final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.343335Z",
     "iopub.status.busy": "2025-03-14T07:06:58.343031Z",
     "iopub.status.idle": "2025-03-14T07:06:58.366713Z",
     "shell.execute_reply": "2025-03-14T07:06:58.365861Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.343305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def analyze_prediction_differences(file_paths, class_names=None):\n",
    "    \"\"\"\n",
    "    Analyzes and visualizes differences between prediction files\n",
    "    \"\"\"\n",
    "    if class_names is None:\n",
    "        class_names = [\n",
    "            'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "            'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "        ]\n",
    "    \n",
    "    dataframes = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.sort_values('ID')\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    agreement_count = 0\n",
    "    class_disagreements = {i: 0 for i in range(len(class_names))}\n",
    "    \n",
    "    for i in range(len(dataframes[0])):\n",
    "        preds = [df.iloc[i]['Labels'] for df in dataframes]\n",
    "        if len(set(preds)) == 1:\n",
    "            agreement_count += 1\n",
    "        else:\n",
    "            for pred in preds:\n",
    "                class_disagreements[pred] += 1\n",
    "    \n",
    "    agreement_rate = agreement_count / len(dataframes[0]) * 100\n",
    "    \n",
    "    print(f\"Agreement rate between prediction files: {agreement_rate:.2f}%\")\n",
    "    print(\"\\nDisagreements by class:\")\n",
    "    for class_idx, count in class_disagreements.items():\n",
    "        print(f\"{class_names[class_idx]}: {count} disagreements\")\n",
    "    \n",
    "    return agreement_rate, class_disagreements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution Pipeline\n",
    "\n",
    "This function orchestrates the complete prediction workflow for generating optimal CIFAR-10 test set submissions:\n",
    "\n",
    "### Multi-Stage Process:\n",
    "\n",
    "1. **Multiple Prediction Generation**:\n",
    "  - Creates three distinct prediction files using different strategies\n",
    "  - Builds a diverse foundation for the ensemble system\n",
    "\n",
    "2. **Ensemble Combination**:\n",
    "  - Forms a consensus prediction using majority voting across all methods\n",
    "  - Creates \"ensemble_submission.csv\" as a robust prediction option\n",
    "\n",
    "3. **Adaptive Single-Pass Prediction**:\n",
    "  - Generates an optimized prediction using the adaptive hybrid approach\n",
    "  - Creates \"final_submission.csv\" as our primary recommendation\n",
    "\n",
    "4. **Comparative Analysis**:\n",
    "  - Evaluates agreement rates between all prediction methods\n",
    "  - Identifies classes with highest prediction divergence\n",
    "  - Provides insights into model confidence and potential weaknesses\n",
    "\n",
    "5. **Recommendation System**:\n",
    "  - Offers a primary and alternative submission option\n",
    "  - Leverages insights from all approaches to maximize final accuracy\n",
    "\n",
    "This comprehensive pipeline maximizes our chances of achieving the highest possible accuracy by leveraging multiple prediction strategies and providing data-driven submission recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:06:58.367684Z",
     "iopub.status.busy": "2025-03-14T07:06:58.367468Z",
     "iopub.status.idle": "2025-03-14T07:06:58.387583Z",
     "shell.execute_reply": "2025-03-14T07:06:58.386795Z",
     "shell.execute_reply.started": "2025-03-14T07:06:58.367666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main(model_path, pkl_file_path):\n",
    "    print(f\"Starting prediction process with model: {model_path}\")\n",
    "    print(f\"Test data: {pkl_file_path}\")\n",
    "    \n",
    "    # Method 1: Generate 3 different prediction files\n",
    "    generate_multiple_predictions(model_path, pkl_file_path)\n",
    "    \n",
    "    # Method 2: Create ensemble from the 3 prediction files\n",
    "    ensemble_prediction_files(\n",
    "        [\n",
    "            \"submission_tta.csv\",\n",
    "            \"submission_spec.csv\",\n",
    "            \"submission_adaptive.csv\"\n",
    "        ],\n",
    "        \"ensemble_submission.csv\"\n",
    "    )\n",
    "    \n",
    "    # Method 3: Create adaptive prediction directly\n",
    "    adaptive_prediction(model_path, pkl_file_path, \"final_submission.csv\")\n",
    "    \n",
    "    print(\"\\nAnalyzing prediction differences:\")\n",
    "    analyze_prediction_differences([\n",
    "        \"submission_tta.csv\",\n",
    "        \"submission_spec.csv\",\n",
    "        \"submission_adaptive.csv\",\n",
    "        \"ensemble_submission.csv\",\n",
    "        \"final_submission.csv\"\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nRecommended submission file: final_submission.csv\")\n",
    "    print(\"Alternative submission file: ensemble_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T07:10:25.024188Z",
     "iopub.status.busy": "2025-03-14T07:10:25.023847Z",
     "iopub.status.idle": "2025-03-14T07:14:09.066201Z",
     "shell.execute_reply": "2025-03-14T07:14:09.065167Z",
     "shell.execute_reply.started": "2025-03-14T07:10:25.024157Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction process with model: /kaggle/input/best_ema_model_500epoch_95.30/pytorch/default/1/best_ema_model.pth\n",
      "Test data: /kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "Generating multiple predictions for ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-31cbb65df9c6>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enhanced TTA prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing augmentations: 100%|██████████| 6/6 [00:27<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced TTA submission file created: submission_tta.csv\n",
      "Starting class-specialized prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial prediction pass: 100%|██████████| 157/157 [00:03<00:00, 45.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6818 low confidence predictions (68.18%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing difficult cases: 100%|██████████| 8/8 [00:30<00:00,  3.77s/it]\n",
      "<ipython-input-56-32a7881ab39a>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-specialized submission file created: submission_spec.csv\n",
      "Starting adaptive prediction process...\n",
      "Successfully loaded model with enhanced architecture\n",
      "\n",
      "Step 1: Running enhanced TTA prediction...\n",
      "Starting enhanced TTA prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing augmentations: 100%|██████████| 8/8 [00:40<00:00,  5.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced TTA submission file created: tmp_tta.csv\n",
      "\n",
      "Step 2: Running class-specialized prediction...\n",
      "Starting class-specialized prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial prediction pass: 100%|██████████| 157/157 [00:03<00:00, 41.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6818 low confidence predictions (68.18%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing difficult cases: 100%|██████████| 8/8 [00:29<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-specialized submission file created: tmp_spec.csv\n",
      "\n",
      "Step 3: Combining predictions adaptively...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing confidence scores: 100%|██████████| 157/157 [00:03<00:00, 51.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive submission file created: submission_adaptive.csv\n",
      "Generated 3 prediction files for ensemble submission\n",
      "Creating ensemble from 3 prediction files...\n",
      "Ensemble submission file created: ensemble_submission.csv\n",
      "Starting adaptive prediction process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-32a7881ab39a>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model with enhanced architecture\n",
      "\n",
      "Step 1: Running enhanced TTA prediction...\n",
      "Starting enhanced TTA prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing augmentations: 100%|██████████| 8/8 [00:39<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced TTA submission file created: tmp_tta.csv\n",
      "\n",
      "Step 2: Running class-specialized prediction...\n",
      "Starting class-specialized prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initial prediction pass: 100%|██████████| 157/157 [00:03<00:00, 41.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6818 low confidence predictions (68.18%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing difficult cases: 100%|██████████| 8/8 [00:30<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-specialized submission file created: tmp_spec.csv\n",
      "\n",
      "Step 3: Combining predictions adaptively...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing confidence scores: 100%|██████████| 157/157 [00:03<00:00, 51.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive submission file created: final_submission.csv\n",
      "\n",
      "Analyzing prediction differences:\n",
      "Agreement rate between prediction files: 97.16%\n",
      "\n",
      "Disagreements by class:\n",
      "airplane: 171 disagreements\n",
      "automobile: 123 disagreements\n",
      "bird: 177 disagreements\n",
      "cat: 252 disagreements\n",
      "deer: 97 disagreements\n",
      "dog: 159 disagreements\n",
      "frog: 94 disagreements\n",
      "horse: 98 disagreements\n",
      "ship: 110 disagreements\n",
      "truck: 139 disagreements\n",
      "\n",
      "Recommended submission file: final_submission.csv\n",
      "Alternative submission file: ensemble_submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    MODEL_PATH = '/kaggle/input/best_ema_model_500epoch_95.30/pytorch/default/1/best_ema_model.pth'\n",
    "    TEST_DATA_PATH = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n",
    "\n",
    "main(MODEL_PATH, TEST_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "isSourceIdPinned": false,
     "sourceId": 93057,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 266517,
     "modelInstanceId": 244910,
     "sourceId": 285744,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
