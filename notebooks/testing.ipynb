{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":93057,"databundleVersionId":11145869,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":285744,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":244910,"modelId":266517}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Setup and Imports\n\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\nimport os\nimport gc\n\n# Set device\ndevice = torch.device('mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu'))\nprint(f\"Using device: {device}\")\n\n# For reproducibility\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\nnp.random.seed(42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.100047Z","iopub.execute_input":"2025-03-14T07:06:58.100404Z","iopub.status.idle":"2025-03-14T07:06:58.109299Z","shell.execute_reply.started":"2025-03-14T07:06:58.100365Z","shell.execute_reply":"2025-03-14T07:06:58.108386Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Model Architecture - Spatial Attention Module\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        padding = kernel_size // 2\n        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        # Generate spatial attention map\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        attention = torch.cat([avg_out, max_out], dim=1)\n        attention = self.conv(attention)\n        attention = self.sigmoid(attention)\n        \n        return x * attention","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.110511Z","iopub.execute_input":"2025-03-14T07:06:58.110794Z","iopub.status.idle":"2025-03-14T07:06:58.127874Z","shell.execute_reply.started":"2025-03-14T07:06:58.110774Z","shell.execute_reply":"2025-03-14T07:06:58.126875Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Model Architecture - Attention Residual Block\n\nclass AttentionResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(AttentionResidualBlock, self).__init__()\n        \n        # Main path\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n                               stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        \n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Channel attention\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        \n        reduction = max(out_channels // 16, 4)  # Ensure at least 4 channels\n        self.channel_attention = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels // reduction, 1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels // reduction, out_channels, 1, bias=False),\n            nn.Sigmoid()\n        )\n        \n        # Spatial attention\n        self.spatial_attention = SpatialAttention(kernel_size=7)\n        \n        # Shortcut connection\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n                          stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x):\n        identity = x\n        \n        # Main path\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        \n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Channel attention\n        avg_out = self.channel_attention(self.avg_pool(out))\n        max_out = self.channel_attention(self.max_pool(out))\n        out = out * (avg_out + max_out)\n        \n        # Spatial attention\n        out = self.spatial_attention(out)\n        \n        # Residual connection\n        identity = self.shortcut(identity)\n        out += identity\n        out = self.relu(out)\n        \n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.129700Z","iopub.execute_input":"2025-03-14T07:06:58.130005Z","iopub.status.idle":"2025-03-14T07:06:58.152267Z","shell.execute_reply.started":"2025-03-14T07:06:58.129983Z","shell.execute_reply":"2025-03-14T07:06:58.151663Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Model Architecture - Enhanced Efficient ResNet\n\nclass EnhancedEfficientResNet(nn.Module):\n    def __init__(self, num_classes=10, base_width=32):\n        super(EnhancedEfficientResNet, self).__init__()\n        \n        # Initial convolution\n        self.conv1 = nn.Conv2d(3, base_width, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(base_width)\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Layer configurations\n        self.layer1 = self._make_layer(base_width, base_width*2, 2, stride=1)\n        self.layer2 = self._make_layer(base_width*2, base_width*4, 2, stride=2)\n        self.layer3 = self._make_layer(base_width*4, base_width*8, 2, stride=2)\n        self.layer4 = self._make_layer(base_width*8, base_width*8, 2, stride=1)  # New layer\n        \n        # Global pooling and classifier\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(base_width*8, num_classes)\n    \n    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n        layers = [\n            AttentionResidualBlock(in_channels, out_channels, stride)\n        ]\n        \n        for _ in range(1, blocks):\n            layers.append(\n                AttentionResidualBlock(out_channels, out_channels)\n            )\n        \n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.153563Z","iopub.execute_input":"2025-03-14T07:06:58.153888Z","iopub.status.idle":"2025-03-14T07:06:58.173471Z","shell.execute_reply.started":"2025-03-14T07:06:58.153858Z","shell.execute_reply":"2025-03-14T07:06:58.172721Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Model Architecture - Original Model (for compatibility)\n\nclass ChannelAttentionBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ChannelAttentionBlock, self).__init__()\n        \n        # Main path\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n                               stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        \n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        # Channel attention\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        \n        reduction = max(out_channels // 16, 4)  # Ensure at least 4 channels\n        self.attention = nn.Sequential(\n            nn.Conv2d(out_channels, out_channels // reduction, 1, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels // reduction, out_channels, 1, bias=False),\n            nn.Sigmoid()\n        )\n        \n        # Shortcut connection\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, \n                          stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n    \n    def forward(self, x):\n        identity = x\n        \n        # Main path\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        \n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        # Channel attention\n        avg_out = self.attention(self.avg_pool(out))\n        max_out = self.attention(self.max_pool(out))\n        out = out * (avg_out + max_out)\n        \n        # Residual connection\n        identity = self.shortcut(identity)\n        out += identity\n        out = self.relu(out)\n        \n        return out\n\nclass EfficientResNet(nn.Module):\n    def __init__(self, num_classes=10, base_width=32):\n        super(EfficientResNet, self).__init__()\n        \n        # Initial convolution\n        self.conv1 = nn.Conv2d(3, base_width, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(base_width)\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Layer configurations\n        self.layer1 = self._make_layer(base_width, base_width*2, 2, stride=1)\n        self.layer2 = self._make_layer(base_width*2, base_width*4, 2, stride=2)\n        self.layer3 = self._make_layer(base_width*4, base_width*8, 2, stride=2)\n        \n        # Global pooling and classifier\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.25)\n        self.fc = nn.Linear(base_width*8, num_classes)\n    \n    def _make_layer(self, in_channels, out_channels, blocks, stride=1):\n        layers = [\n            ChannelAttentionBlock(in_channels, out_channels, stride)\n        ]\n        \n        for _ in range(1, blocks):\n            layers.append(\n                ChannelAttentionBlock(out_channels, out_channels)\n            )\n        \n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.174328Z","iopub.execute_input":"2025-03-14T07:06:58.174565Z","iopub.status.idle":"2025-03-14T07:06:58.196146Z","shell.execute_reply.started":"2025-03-14T07:06:58.174534Z","shell.execute_reply":"2025-03-14T07:06:58.195494Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Test Time Augmentation Setup\n\n# Define test-time normalization for CIFAR-10\ntest_normalization = transforms.Normalize(\n    mean=(0.4914, 0.4822, 0.4465), \n    std=(0.2023, 0.1994, 0.2010)\n)\n\n# Advanced test-time augmentation transforms\nadvanced_transforms = [\n    # 1. Original transform (base)\n    transforms.Compose([\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n    # 2. Horizontal flip\n    transforms.Compose([\n        transforms.RandomHorizontalFlip(p=1.0),\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n    # 3. Small crop 1\n    transforms.Compose([\n        transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n    # 4. Small crop 2 (different padding)\n    transforms.Compose([\n        transforms.RandomCrop(32, padding=4, padding_mode='edge'),\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n    # 5. Slight rotate 1\n    transforms.Compose([\n        transforms.RandomRotation(5),\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n    # 6. Slight rotate 2\n    transforms.Compose([\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n    # 7. Color jitter\n    transforms.Compose([\n        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n    # 8. Color jitter 2\n    transforms.Compose([\n        transforms.ColorJitter(brightness=0.05, contrast=0.15, saturation=0.05, hue=0),\n        transforms.ToTensor(),\n        test_normalization,\n    ]),\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.196927Z","iopub.execute_input":"2025-03-14T07:06:58.197190Z","iopub.status.idle":"2025-03-14T07:06:58.218183Z","shell.execute_reply.started":"2025-03-14T07:06:58.197170Z","shell.execute_reply":"2025-03-14T07:06:58.217242Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# Custom CIFAR Test Dataset with Enhanced Data Handling\n\nclass EnhancedCIFARTestDataset(Dataset):\n    def __init__(self, pkl_file_path, transform=None):\n        \"\"\"\n        Args:\n            pkl_file_path (string): Path to the .pkl file containing test data\n            transform (callable, optional): Transform to be applied on a sample\n        \"\"\"\n        self.transform = transform\n        \n        # Load and process test data with error handling\n        try:\n            with open(pkl_file_path, 'rb') as f:\n                data = pickle.load(f, encoding='bytes')\n            \n            # Extract images and IDs\n            self.images = data[b'data']\n            self.ids = data[b'ids'] if b'ids' in data else np.arange(len(self.images))\n            \n            # Handle different data formats\n            if len(self.images.shape) == 2:\n                # If images are stored as flat arrays (N, 3072), reshape\n                print(f\"Reshaping flat images of shape {self.images.shape}\")\n                self.images = self.images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n                print(f\"Reshaped to {self.images.shape}\")\n        except Exception as e:\n            print(f\"Error loading data: {e}\")\n            raise\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        # Convert numpy array to PIL Image with proper error handling\n        try:\n            image = self.images[idx]\n            if not isinstance(image, Image.Image):\n                image = Image.fromarray(image.astype('uint8'))\n            \n            if self.transform:\n                image = self.transform(image)\n            \n            return image, self.ids[idx]\n        except Exception as e:\n            print(f\"Error processing image {idx}: {e}\")\n            # Return a dummy image as fallback\n            if self.transform:\n                return torch.zeros(3, 32, 32), self.ids[idx]\n            else:\n                return np.zeros((32, 32, 3), dtype=np.uint8), self.ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.219292Z","iopub.execute_input":"2025-03-14T07:06:58.219623Z","iopub.status.idle":"2025-03-14T07:06:58.237754Z","shell.execute_reply.started":"2025-03-14T07:06:58.219591Z","shell.execute_reply":"2025-03-14T07:06:58.237117Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Enhanced Test-Time Augmentation Prediction\n\ndef enhanced_tta_prediction(model, pkl_file_path, output_filename=\"enhanced_submission.csv\", num_transforms=8):\n    \"\"\"\n    Advanced test-time augmentation with weighted averaging of predictions\n    \"\"\"\n    print(\"Starting enhanced TTA prediction...\")\n    model.eval()\n    \n    # Select requested number of transforms\n    transforms_to_use = advanced_transforms[:num_transforms]\n    \n    # Weights for different transforms (giving higher weight to original image)\n    weights = [2.0]  # Increase from 1.5 to 2.0\n    weights.extend([1.0] * (len(transforms_to_use) - 1))\n    \n    # Normalize weights\n    weights = [w / sum(weights) for w in weights]\n    \n    # Storage for all predictions\n    all_probs = []\n    image_ids = None\n    \n    # Process each transform\n    for i, transform in enumerate(tqdm(transforms_to_use, desc=\"Processing augmentations\")):\n        # Create dataset with this transform\n        dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=transform)\n        dataloader = DataLoader(\n            dataset, \n            batch_size=32,  # Smaller batch size to avoid OOM\n            shuffle=False, \n            num_workers=2, \n            pin_memory=True\n        )\n        \n        # Collect batch predictions\n        batch_probs = []\n        batch_ids = []\n        \n        with torch.no_grad():\n            for images, ids in dataloader:\n                images = images.to(device)\n                outputs = model(images)\n                \n                # Apply temperature scaling for better calibration\n                outputs = outputs / 0.9  # Temperature parameter\n                \n                # Get softmax probabilities\n                probs = F.softmax(outputs, dim=1)\n                \n                batch_probs.append(probs.cpu().numpy())\n                batch_ids.append(ids.numpy())\n                \n                # Free up memory\n                del images, outputs, probs\n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n        \n        # Concatenate all batches\n        augmentation_probs = np.concatenate(batch_probs)\n        \n        # Apply weight to this augmentation's predictions\n        all_probs.append(augmentation_probs * weights[i])\n        \n        # Store IDs (same for all augmentations)\n        if image_ids is None:\n            image_ids = np.concatenate(batch_ids)\n        \n        # Free memory\n        del batch_probs, augmentation_probs\n        gc.collect()\n    \n    # Combine predictions by averaging softmax probabilities\n    avg_probs = np.sum(all_probs, axis=0)\n    final_preds = np.argmax(avg_probs, axis=1)\n    \n    # Create and save submission\n    submission_df = pd.DataFrame({\n        'ID': image_ids, \n        'Labels': final_preds\n    })\n    submission_df = submission_df.sort_values('ID')\n    submission_df.to_csv(output_filename, index=False)\n    print(f\"Enhanced TTA submission file created: {output_filename}\")\n    return submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.239636Z","iopub.execute_input":"2025-03-14T07:06:58.239864Z","iopub.status.idle":"2025-03-14T07:06:58.261434Z","shell.execute_reply.started":"2025-03-14T07:06:58.239845Z","shell.execute_reply":"2025-03-14T07:06:58.260649Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Class-Specialized Prediction Handling\n\ndef class_specialized_prediction(model, pkl_file_path, output_filename=\"specialized_submission.csv\"):\n    \"\"\"\n    Creates predictions with specialized handling for different classes based on confidence thresholds\n    \"\"\"\n    print(\"Starting class-specialized prediction...\")\n    model.eval()\n    \n    # Initial pass with base transform\n    base_transform = advanced_transforms[0]\n    dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=base_transform)\n    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n    \n    # First pass - get initial predictions and confidence\n    initial_preds = []\n    confidence_scores = []\n    image_ids = []\n    \n    with torch.no_grad():\n        for images, ids in tqdm(dataloader, desc=\"Initial prediction pass\"):\n            images = images.to(device)\n            outputs = model(images)\n            \n            # Get softmax probabilities\n            probs = F.softmax(outputs, dim=1)\n            \n            # Get predictions and confidence\n            values, preds = torch.max(probs, dim=1)\n            \n            initial_preds.extend(preds.cpu().numpy())\n            confidence_scores.extend(values.cpu().numpy())\n            image_ids.extend(ids.numpy())\n            \n            # Free memory\n            del images, outputs, probs, values, preds\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n    \n    # Confidence thresholds for different classes - based on common confusion patterns\n    class_confidence_thresholds = {\n        0: 0.85,  # airplane\n        1: 0.90,  # automobile\n        2: 0.75,  # bird - still relatively difficult\n        3: 0.70,  # cat - difficult class\n        4: 0.75,  # deer\n        5: 0.70,  # dog - difficult class\n        6: 0.85,  # frog\n        7: 0.85,  # horse\n        8: 0.90,  # ship\n        9: 0.90,  # truck\n    }\n    \n    # Identify low confidence predictions\n    low_conf_indices = []\n    for i, (pred, conf) in enumerate(zip(initial_preds, confidence_scores)):\n        if conf < class_confidence_thresholds.get(pred, 0.75):\n            low_conf_indices.append(i)\n    \n    print(f\"Found {len(low_conf_indices)} low confidence predictions ({len(low_conf_indices)/len(initial_preds)*100:.2f}%)\")\n    \n    # For low confidence predictions, use enhanced TTA\n    final_preds = list(initial_preds)\n    \n    if low_conf_indices:\n        # Process all transforms for low confidence cases only\n        low_conf_probs = []\n        \n        for transform in tqdm(advanced_transforms, desc=\"Processing difficult cases\"):\n            dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=transform)\n            dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n            \n            all_outputs = []\n            \n            with torch.no_grad():\n                for batch_idx, (images, _) in enumerate(dataloader):\n                    # Only process batches that contain low confidence samples\n                    batch_start = batch_idx * 64\n                    batch_end = min(batch_start + 64, len(dataset))\n                    batch_indices = list(range(batch_start, batch_end))\n                    \n                    # Check if any low confidence indices are in this batch\n                    process_batch = any(idx in low_conf_indices for idx in batch_indices)\n                    \n                    if process_batch:\n                        images = images.to(device)\n                        outputs = model(images)\n                        all_outputs.append(outputs.cpu())\n                    else:\n                        # Skip this batch by adding dummy outputs\n                        all_outputs.append(torch.zeros(len(batch_indices), 10))\n            \n            # Concatenate all outputs\n            all_outputs = torch.cat(all_outputs)\n            \n            # Extract only the low confidence predictions\n            selected_outputs = all_outputs[low_conf_indices]\n            selected_probs = F.softmax(selected_outputs / 1.2, dim=1).numpy()  # Apply temperature\n            \n            low_conf_probs.append(selected_probs)\n            \n            # Free memory\n            del all_outputs, selected_outputs, selected_probs\n            gc.collect()\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n        \n        # Average probabilities for low confidence predictions\n        avg_probs = np.mean(np.stack(low_conf_probs), axis=0)\n        improved_preds = np.argmax(avg_probs, axis=1)\n        \n        # Update predictions for low confidence cases\n        for i, idx in enumerate(low_conf_indices):\n            final_preds[idx] = improved_preds[i]\n    \n    # Create and save submission\n    submission_df = pd.DataFrame({\n        'ID': image_ids, \n        'Labels': final_preds\n    })\n    submission_df = submission_df.sort_values('ID')\n    submission_df.to_csv(output_filename, index=False)\n    print(f\"Class-specialized submission file created: {output_filename}\")\n    return submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.262465Z","iopub.execute_input":"2025-03-14T07:06:58.262752Z","iopub.status.idle":"2025-03-14T07:06:58.276473Z","shell.execute_reply.started":"2025-03-14T07:06:58.262732Z","shell.execute_reply":"2025-03-14T07:06:58.275808Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Adaptive Combination of Multiple Prediction Methods\n\ndef adaptive_prediction(model_path, pkl_file_path, output_filename=\"adaptive_submission.csv\"):\n    \"\"\"\n    Creates predictions using an adaptive approach that combines multiple techniques\n    \"\"\"\n    print(\"Starting adaptive prediction process...\")\n    \n    # Load model\n    try:\n        # First try the enhanced model architecture\n        model = EnhancedEfficientResNet(num_classes=10)\n        model.load_state_dict(torch.load(model_path, map_location=device))\n        print(\"Successfully loaded model with enhanced architecture\")\n    except:\n        try:\n            # Fall back to original architecture\n            model = EfficientResNet(num_classes=10)\n            model.load_state_dict(torch.load(model_path, map_location=device))\n            print(\"Successfully loaded model with original architecture\")\n        except Exception as e:\n            print(f\"Error loading model: {e}\")\n            print(\"Attempting alternative loading method...\")\n            \n            # Try loading just the state dict\n            model = EnhancedEfficientResNet(num_classes=10)\n            state_dict = torch.load(model_path, map_location=device)\n            if isinstance(state_dict, dict) and 'state_dict' in state_dict:\n                model.load_state_dict(state_dict['state_dict'])\n            else:\n                model.load_state_dict(state_dict, strict=False)\n                print(\"Warning: Model loaded with strict=False, some weights may not be loaded\")\n    \n    model = model.to(device)\n    model.eval()\n    \n    # Step 1: Run enhanced TTA\n    print(\"\\nStep 1: Running enhanced TTA prediction...\")\n    enhanced_tta_prediction(model, pkl_file_path, \"tmp_tta.csv\", num_transforms=8)\n    \n    # Step 2: Run class-specialized prediction\n    print(\"\\nStep 2: Running class-specialized prediction...\")\n    class_specialized_prediction(model, pkl_file_path, \"tmp_spec.csv\")\n    \n    # Step 3: Combine predictions based on confidence\n    print(\"\\nStep 3: Combining predictions adaptively...\")\n    \n    # Load both prediction files\n    tta_df = pd.read_csv(\"tmp_tta.csv\")\n    spec_df = pd.read_csv(\"tmp_spec.csv\")\n    \n    # Ensure they have the same order\n    tta_df = tta_df.sort_values('ID')\n    spec_df = spec_df.sort_values('ID')\n    \n    # Get confidence scores for all predictions\n    base_transform = advanced_transforms[0]\n    dataset = EnhancedCIFARTestDataset(pkl_file_path, transform=base_transform)\n    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n    \n    all_probs = []\n    all_ids = []\n    \n    with torch.no_grad():\n        for images, ids in tqdm(dataloader, desc=\"Computing confidence scores\"):\n            images = images.to(device)\n            outputs = model(images)\n            probs = F.softmax(outputs, dim=1)\n            all_probs.append(probs.cpu().numpy())\n            all_ids.extend(ids.numpy())\n    \n    all_probs = np.concatenate(all_probs)\n    id_to_index = {id_val: i for i, id_val in enumerate(all_ids)}\n    \n    # Combine predictions\n    final_labels = []\n    \n    # Thresholds for decision making\n    HIGH_CONF = 0.95  # Increase from 0.90\n    MED_CONF = 0.80   # Increase from 0.75\n    \n    # Additional confidence boosting for specific classes\n    class_boost = {\n        2: 0.05,  # bird\n        3: 0.05,  # cat\n        5: 0.05,  # dog\n    }\n    \n    for i in range(len(tta_df)):\n        img_id = tta_df.iloc[i]['ID']\n        tta_pred = tta_df.iloc[i]['Labels']\n        spec_pred = spec_df.loc[spec_df['ID'] == img_id, 'Labels'].values[0]\n        \n        # Get confidence for both predictions\n        idx = id_to_index[img_id]\n        prob_vector = all_probs[idx]\n        \n        # Apply confidence boosting for certain classes\n        tta_conf = prob_vector[tta_pred]\n        if tta_pred in class_boost:\n            tta_conf += class_boost[tta_pred]\n            \n        spec_conf = prob_vector[spec_pred]\n        if spec_pred in class_boost:\n            spec_conf += class_boost[spec_pred]\n        \n        # Decision logic\n        if tta_pred == spec_pred:\n            # Both methods agree\n            final_labels.append(tta_pred)\n        elif tta_conf > HIGH_CONF:\n            # TTA prediction has very high confidence\n            final_labels.append(tta_pred)\n        elif spec_conf > HIGH_CONF:\n            # Class specialized prediction has very high confidence\n            final_labels.append(spec_pred)\n        elif tta_conf > MED_CONF and tta_conf > spec_conf:\n            # TTA has decent confidence and higher than class specialized\n            final_labels.append(tta_pred)\n        elif spec_conf > MED_CONF and spec_conf > tta_conf:\n            # Class specialized has decent confidence and higher than TTA\n            final_labels.append(spec_pred)\n        elif tta_pred in [2, 3, 5]:\n            # For difficult classes, prefer specialized prediction\n            final_labels.append(spec_pred)\n        else:\n            # Default to enhanced TTA\n            final_labels.append(tta_pred)\n    \n    # Create final submission\n    submission_df = pd.DataFrame({\n        'ID': tta_df['ID'],\n        'Labels': final_labels\n    })\n    submission_df.to_csv(output_filename, index=False)\n    \n    # Clean up temporary files\n    if os.path.exists(\"tmp_tta.csv\"):\n        os.remove(\"tmp_tta.csv\")\n    if os.path.exists(\"tmp_spec.csv\"):\n        os.remove(\"tmp_spec.csv\")\n    \n    print(f\"Adaptive submission file created: {output_filename}\")\n    return submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.277328Z","iopub.execute_input":"2025-03-14T07:06:58.277563Z","iopub.status.idle":"2025-03-14T07:06:58.300196Z","shell.execute_reply.started":"2025-03-14T07:06:58.277533Z","shell.execute_reply":"2025-03-14T07:06:58.299560Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Generate Multiple Predictions for Ensemble\n\ndef generate_multiple_predictions(model_path, pkl_file_path, base_filename=\"submission\"):\n    \"\"\"\n    Generates multiple prediction files using different methods for final ensemble\n    \"\"\"\n    print(\"Generating multiple predictions for ensemble...\")\n    \n    # Load model\n    try:\n        model = EnhancedEfficientResNet(num_classes=10)\n        model.load_state_dict(torch.load(model_path, map_location=device))\n    except:\n        model = EfficientResNet(num_classes=10)\n        model.load_state_dict(torch.load(model_path, map_location=device))\n    \n    model = model.to(device)\n    model.eval()\n    \n    # Method 1: Enhanced TTA\n    enhanced_tta_prediction(\n        model, \n        pkl_file_path, \n        f\"{base_filename}_tta.csv\",\n        num_transforms=6  # Using fewer transforms for diversity\n    )\n    \n    # Method 2: Class specialized with different thresholds\n    class_specialized_prediction(\n        model,\n        pkl_file_path,\n        f\"{base_filename}_spec.csv\"\n    )\n    \n    # Method 3: Adaptive prediction\n    adaptive_prediction(\n        model_path,\n        pkl_file_path,\n        f\"{base_filename}_adaptive.csv\"\n    )\n    \n    print(f\"Generated 3 prediction files for ensemble submission\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.301005Z","iopub.execute_input":"2025-03-14T07:06:58.301274Z","iopub.status.idle":"2025-03-14T07:06:58.320520Z","shell.execute_reply.started":"2025-03-14T07:06:58.301246Z","shell.execute_reply":"2025-03-14T07:06:58.319985Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Ensemble Multiple Prediction Files\n\ndef ensemble_prediction_files(file_paths, output_filename=\"ensemble_submission.csv\"):\n    \"\"\"\n    Ensembles multiple prediction CSV files\n    \"\"\"\n    print(f\"Creating ensemble from {len(file_paths)} prediction files...\")\n    \n    # Load all prediction files\n    dataframes = []\n    for file_path in file_paths:\n        df = pd.read_csv(file_path)\n        df = df.sort_values('ID')\n        dataframes.append(df)\n    \n    # Ensure all dataframes have the same IDs\n    for i in range(1, len(dataframes)):\n        assert np.array_equal(dataframes[0]['ID'].values, dataframes[i]['ID'].values), \"ID mismatch between files\"\n    \n    # Get predictions from each file\n    all_preds = np.array([df['Labels'].values for df in dataframes])\n    \n    # Get majority vote for each sample\n    final_preds = []\n    for i in range(len(dataframes[0])):\n        sample_preds = all_preds[:, i]\n        values, counts = np.unique(sample_preds, return_counts=True)\n        max_count_idx = np.argmax(counts)\n        final_preds.append(values[max_count_idx])\n    \n    # Create final submission\n    ensemble_df = pd.DataFrame({\n        'ID': dataframes[0]['ID'],\n        'Labels': final_preds\n    })\n    ensemble_df.to_csv(output_filename, index=False)\n    print(f\"Ensemble submission file created: {output_filename}\")\n    return ensemble_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.321287Z","iopub.execute_input":"2025-03-14T07:06:58.321561Z","iopub.status.idle":"2025-03-14T07:06:58.342143Z","shell.execute_reply.started":"2025-03-14T07:06:58.321533Z","shell.execute_reply":"2025-03-14T07:06:58.341415Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# Analyze Prediction Differences\n\ndef analyze_prediction_differences(file_paths, class_names=None):\n    \"\"\"\n    Analyzes and visualizes differences between prediction files\n    \"\"\"\n    if class_names is None:\n        class_names = [\n            'airplane', 'automobile', 'bird', 'cat', 'deer',\n            'dog', 'frog', 'horse', 'ship', 'truck'\n        ]\n    \n    # Load all prediction files\n    dataframes = []\n    for file_path in file_paths:\n        df = pd.read_csv(file_path)\n        df = df.sort_values('ID')\n        dataframes.append(df)\n    \n    # Compute agreement rate\n    agreement_count = 0\n    class_disagreements = {i: 0 for i in range(len(class_names))}\n    \n    for i in range(len(dataframes[0])):\n        preds = [df.iloc[i]['Labels'] for df in dataframes]\n        if len(set(preds)) == 1:\n            agreement_count += 1\n        else:\n            # Track which classes have disagreements\n            for pred in preds:\n                class_disagreements[pred] += 1\n    \n    agreement_rate = agreement_count / len(dataframes[0]) * 100\n    \n    print(f\"Agreement rate between prediction files: {agreement_rate:.2f}%\")\n    print(\"\\nDisagreements by class:\")\n    for class_idx, count in class_disagreements.items():\n        print(f\"{class_names[class_idx]}: {count} disagreements\")\n    \n    return agreement_rate, class_disagreements","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.343031Z","iopub.execute_input":"2025-03-14T07:06:58.343335Z","iopub.status.idle":"2025-03-14T07:06:58.366713Z","shell.execute_reply.started":"2025-03-14T07:06:58.343305Z","shell.execute_reply":"2025-03-14T07:06:58.365861Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Main Execution Function\n\ndef main(model_path, pkl_file_path):\n    print(f\"Starting prediction process with model: {model_path}\")\n    print(f\"Test data: {pkl_file_path}\")\n    \n    # Method 1: Generate 3 different prediction files\n    generate_multiple_predictions(model_path, pkl_file_path)\n    \n    # Method 2: Create ensemble from the 3 prediction files\n    ensemble_prediction_files(\n        [\n            \"submission_tta.csv\",\n            \"submission_spec.csv\",\n            \"submission_adaptive.csv\"\n        ],\n        \"ensemble_submission.csv\"\n    )\n    \n    # Method 3: Create adaptive prediction directly\n    adaptive_prediction(model_path, pkl_file_path, \"final_submission.csv\")\n    \n    # Analyze differences between the prediction files\n    print(\"\\nAnalyzing prediction differences:\")\n    analyze_prediction_differences([\n        \"submission_tta.csv\",\n        \"submission_spec.csv\",\n        \"submission_adaptive.csv\",\n        \"ensemble_submission.csv\",\n        \"final_submission.csv\"\n    ])\n    \n    print(\"\\nRecommended submission file: final_submission.csv\")\n    print(\"Alternative submission file: ensemble_submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:06:58.367468Z","iopub.execute_input":"2025-03-14T07:06:58.367684Z","iopub.status.idle":"2025-03-14T07:06:58.387583Z","shell.execute_reply.started":"2025-03-14T07:06:58.367666Z","shell.execute_reply":"2025-03-14T07:06:58.386795Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# Run the Code (update paths as needed)\n\nif __name__ == \"__main__\":\n    # Paths for Kaggle environment - update these for your environment\n    MODEL_PATH = '/kaggle/input/best_ema_model_500epoch_95.30/pytorch/default/1/best_ema_model.pth'\n    TEST_DATA_PATH = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\n\nmain(MODEL_PATH, TEST_DATA_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T07:10:25.023847Z","iopub.execute_input":"2025-03-14T07:10:25.024188Z","iopub.status.idle":"2025-03-14T07:14:09.066201Z","shell.execute_reply.started":"2025-03-14T07:10:25.024157Z","shell.execute_reply":"2025-03-14T07:14:09.065167Z"}},"outputs":[{"name":"stdout","text":"Starting prediction process with model: /kaggle/input/best_ema_model_500epoch_95.30/pytorch/default/1/best_ema_model.pth\nTest data: /kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\nGenerating multiple predictions for ensemble...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-57-31cbb65df9c6>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Starting enhanced TTA prediction...\n","output_type":"stream"},{"name":"stderr","text":"Processing augmentations: 100%|██████████| 6/6 [00:27<00:00,  4.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Enhanced TTA submission file created: submission_tta.csv\nStarting class-specialized prediction...\n","output_type":"stream"},{"name":"stderr","text":"Initial prediction pass: 100%|██████████| 157/157 [00:03<00:00, 45.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Found 6818 low confidence predictions (68.18%)\n","output_type":"stream"},{"name":"stderr","text":"Processing difficult cases: 100%|██████████| 8/8 [00:30<00:00,  3.77s/it]\n<ipython-input-56-32a7881ab39a>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Class-specialized submission file created: submission_spec.csv\nStarting adaptive prediction process...\nSuccessfully loaded model with enhanced architecture\n\nStep 1: Running enhanced TTA prediction...\nStarting enhanced TTA prediction...\n","output_type":"stream"},{"name":"stderr","text":"Processing augmentations: 100%|██████████| 8/8 [00:40<00:00,  5.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Enhanced TTA submission file created: tmp_tta.csv\n\nStep 2: Running class-specialized prediction...\nStarting class-specialized prediction...\n","output_type":"stream"},{"name":"stderr","text":"Initial prediction pass: 100%|██████████| 157/157 [00:03<00:00, 41.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Found 6818 low confidence predictions (68.18%)\n","output_type":"stream"},{"name":"stderr","text":"Processing difficult cases: 100%|██████████| 8/8 [00:29<00:00,  3.73s/it]\n","output_type":"stream"},{"name":"stdout","text":"Class-specialized submission file created: tmp_spec.csv\n\nStep 3: Combining predictions adaptively...\n","output_type":"stream"},{"name":"stderr","text":"Computing confidence scores: 100%|██████████| 157/157 [00:03<00:00, 51.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adaptive submission file created: submission_adaptive.csv\nGenerated 3 prediction files for ensemble submission\nCreating ensemble from 3 prediction files...\nEnsemble submission file created: ensemble_submission.csv\nStarting adaptive prediction process...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-56-32a7881ab39a>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Successfully loaded model with enhanced architecture\n\nStep 1: Running enhanced TTA prediction...\nStarting enhanced TTA prediction...\n","output_type":"stream"},{"name":"stderr","text":"Processing augmentations: 100%|██████████| 8/8 [00:39<00:00,  4.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Enhanced TTA submission file created: tmp_tta.csv\n\nStep 2: Running class-specialized prediction...\nStarting class-specialized prediction...\n","output_type":"stream"},{"name":"stderr","text":"Initial prediction pass: 100%|██████████| 157/157 [00:03<00:00, 41.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Found 6818 low confidence predictions (68.18%)\n","output_type":"stream"},{"name":"stderr","text":"Processing difficult cases: 100%|██████████| 8/8 [00:30<00:00,  3.79s/it]\n","output_type":"stream"},{"name":"stdout","text":"Class-specialized submission file created: tmp_spec.csv\n\nStep 3: Combining predictions adaptively...\n","output_type":"stream"},{"name":"stderr","text":"Computing confidence scores: 100%|██████████| 157/157 [00:03<00:00, 51.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Adaptive submission file created: final_submission.csv\n\nAnalyzing prediction differences:\nAgreement rate between prediction files: 97.16%\n\nDisagreements by class:\nairplane: 171 disagreements\nautomobile: 123 disagreements\nbird: 177 disagreements\ncat: 252 disagreements\ndeer: 97 disagreements\ndog: 159 disagreements\nfrog: 94 disagreements\nhorse: 98 disagreements\nship: 110 disagreements\ntruck: 139 disagreements\n\nRecommended submission file: final_submission.csv\nAlternative submission file: ensemble_submission.csv\n","output_type":"stream"}],"execution_count":65}]}